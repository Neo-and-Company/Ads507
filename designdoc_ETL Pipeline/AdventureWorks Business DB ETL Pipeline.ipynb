{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdventureWorks Business DB ETL Pipeline – Design Document\n",
    "\n",
    "**Authors:** Gabriel Mancillas, Duy Nguyen, Jorge Roldan  \n",
    "**Date:** Feb 24, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Repository Overview\n",
    "\n",
    "- **GitHub Repository:**  \n",
    "  [Your GitHub Repo URL Here](https://github.com/Neo-and-Company/Ads507)  \n",
    "  This repository contains:\n",
    "  - Python scripts for Extract, Transform, Load (ETL)\n",
    "  - Database schema (.sql files)\n",
    "  - Documentation for deployment and usage\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Source Datasets\n",
    "\n",
    "#### 2.1. Dataset Origin & Rationale\n",
    "\n",
    "We use AdventureWorks CSV files, which are a well-known sample dataset provided by Microsoft. The dataset includes tables such as:\n",
    "- Employee.csv\n",
    "- Vendor.csv\n",
    "- ShipMethod.csv\n",
    "- Product.csv\n",
    "- PurchaseOrderHeader.csv\n",
    "- PurchaseOrderDetail.csv\n",
    "- Sales.csv (optional for simulation)\n",
    "- SalesTarget.csv (monthly/quarterly targets)\n",
    "- Customer.csv\n",
    "- WeeklySalesSummary.csv (aggregated data)\n",
    "\n",
    "**Why Choose AdventureWorks?**\n",
    "- **Realistic Business Environment:** Simulates manufacturing, sales, and related processes.\n",
    "- **Rich Relationships:** Ideal for practicing SQL joins, foreign keys, and building data warehouses.\n",
    "- **Standard Example:** Widely recognized in the SQL community.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Pipeline Output\n",
    "\n",
    "#### 3.1. What the Pipeline Produces\n",
    "\n",
    "Post-ETL execution, cleaned and transformed data are loaded into MySQL, enabling the following reports:\n",
    "- **Weekly Sales:** Revenue, order counts, average sale values.\n",
    "- **Purchase Order Analysis:** Vendor-product relations, spending totals, order statuses.\n",
    "- **Employee & Sales Performance:** Comparison of SalesTarget vs. actual Sales.\n",
    "\n",
    "#### 3.2. Benefits of the Pipeline\n",
    "\n",
    "- **Business Insights:** Informs decisions on inventory, vendor management, and employee performance.\n",
    "- **Automation:** Ensures up-to-date metrics through scheduled reporting.\n",
    "- **Scalability:** Designed to extend with additional tables and data sources.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Architecture Diagram\n",
    "\n",
    "```\n",
    "         ┌──────────────┐\n",
    "         │ CSV Datasets │\n",
    "         │(Employee.csv,│\n",
    "         │ Vendor.csv,  │\n",
    "         │    ...     )│\n",
    "         └─────┬────────┘\n",
    "               │  (Extract)\n",
    "               ▼\n",
    "     ┌─────────────────────┐\n",
    "     │  Python ETL Scripts │\n",
    "     │(extract, transform, │\n",
    "     │        load)        │\n",
    "     └─────┬───────────────┘\n",
    "           │ (Transform/Load)\n",
    "           ▼\n",
    "     ┌────────────────────────┐\n",
    "     │    MySQL Database      │\n",
    "     │ (Cleaned & Final Tables)│\n",
    "     └─────┬──────────────────┘\n",
    "           │ (Query for Reports)\n",
    "           ▼\n",
    "     ┌─────────────────────────┐\n",
    "     │   Automated Reports     │\n",
    "     │ (Sales, PO analysis,    │\n",
    "     │  Employee insights)     │\n",
    "     └─────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Final Schema Diagram\n",
    "\n",
    "**Key Tables and Relationships:**\n",
    "\n",
    "- **Employee:** EmployeeID (PK)\n",
    "- **Vendor:** VendorID (PK)\n",
    "- **ShipMethod:** ShipMethodID (PK)\n",
    "- **Product:** ProductID (PK)\n",
    "\n",
    "- **PurchaseOrderHeader:**  \n",
    "  - PurchaseOrderID (PK)  \n",
    "  - EmployeeID (FK → Employee(EmployeeID))  \n",
    "  - VendorID (FK → Vendor(VendorID))  \n",
    "  - ShipMethodID (FK → ShipMethod(ShipMethodID))\n",
    "\n",
    "- **PurchaseOrderDetail:**  \n",
    "  - PurchaseOrderDetailID (PK)  \n",
    "  - PurchaseOrderID (FK → PurchaseOrderHeader(PurchaseOrderID))  \n",
    "  - ProductID (FK → Product(ProductID))\n",
    "\n",
    "- **Sales:**  \n",
    "  - SaleID (PK)  \n",
    "  - EmployeeID (FK → Employee(EmployeeID))  \n",
    "  - CustomerID (FK → Customer(CustomerID)) *(optional)*\n",
    "\n",
    "- **SalesTarget:**  \n",
    "  - SalesTargetID (PK) or composite key (EmployeeID, Year, Month)  \n",
    "  - EmployeeID (FK → Employee(EmployeeID))\n",
    "\n",
    "- **WeeklySalesSummary:**  \n",
    "  - Composite Key: (Year, Week)\n",
    "\n",
    "- **Customer:** CustomerID (PK)\n",
    "\n",
    "*(If additional relationships or bridging tables are necessary (e.g., for ShipMethod ↔ Product), adjust accordingly.)*\n",
    "\n",
    "---\n",
    "\n",
    "## 6. System Considerations and Future Improvements\n",
    "\n",
    "#### 6.1. Scalability\n",
    "\n",
    "- **Current Approach:**  \n",
    "  A single MySQL instance with Python-based ETL handles moderate data volumes.\n",
    "\n",
    "- **Potential Bottlenecks and Enhancements:**  \n",
    "  - Table sharding or partitioning for scaling.\n",
    "  - Migrating to distributed databases (e.g., Amazon Redshift, BigQuery).\n",
    "  - Implementing chunk-based or incremental loading to optimize performance.\n",
    "\n",
    "#### 6.2. Security\n",
    "\t- AWS RDS & RDS Proxy:\n",
    "\t- The RDS Proxy can manage database credentials via AWS Secrets Manager, limiting direct access to the DB.\n",
    "\t•\tConnections can be IAM-authenticated or use token-based security.\n",
    "\t•\tToken-Based Access:\n",
    "\t•\tThe application can request temporary credentials/tokens from IAM, reducing the need to store static passwords.\n",
    "\t•\tNetwork:\n",
    "\t•\tDeploy RDS in a private subnet; only the proxy endpoint is exposed to the application.\n",
    "\t•\tUse security groups to restrict inbound connections to known IPs or VPC resources.\n",
    "\t•\tEncryption:\n",
    "\t•\tAt Rest: Use KMS to encrypt RDS data.\n",
    "\t•\tIn Transit: Enforce SSL/TLS connections between the application and the proxy.\n",
    "\n",
    "#### 6.3. Extensibility\n",
    "\n",
    "- **Adding New Tables:**  \n",
    "  The schema is flexible and can integrate additional CSV inputs.\n",
    "- **Adapting Transformations:**  \n",
    "  Python scripts are modular, allowing new transformation functions.\n",
    "- **Alternate Data Outputs:**  \n",
    "  Possibility to connect with BI dashboards or load data into a data warehouse for advanced analytics.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Conclusion\n",
    "\n",
    "This design document describes a robust ETL pipeline that:\n",
    "\t1.\tExtracts AdventureWorks CSV data.\n",
    "\t2.\tTransforms it via Python scripts.\n",
    "\t3.\tLoads final tables into AWS RDS (MySQL) behind an RDS Proxy.\n",
    "\t4.\tSecures credentials using token-based access and AWS Secrets Manager.\n",
    "\t5.\tProduces automated reports on sales, purchase orders, employee metrics, etc.\n",
    "\n",
    "**Strengths:**\n",
    "\t•\tAWS-based deployment with RDS Proxy improves security and performance.\n",
    "\t•\tToken-based authentication removes the need for static credentials.\n",
    "\t•\tPipeline is modular, allowing easy extension.\n",
    "\n",
    "**Areas for Improvement:**\n",
    "\t•\tScaling for very large datasets may require read replicas or a data warehouse approach.\n",
    "\t•\tAdditional security layers (audit logging, stricter IAM roles) can further reduce risk.\n",
    "\n",
    "This pipeline meets typical business intelligence needs and is structured for future expansion and scalability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
